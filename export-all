#!/usr/bin/python
# -*- coding: utf-8 -*-

from __future__ import print_function

import sys
sys.path.append('lib')

import argparse
import datetime
import json
import os
import pytz
import urllib2
import n5core.endpoint

class XMLTag(object):
    def __init__(self, level, fh, tagname, attr=None):
        self.fh = fh
        self.tagname = tagname
        self.attr = attr
        self.level = level


    def __enter__(self):
        if self.attr:
            self.fh.write("%s<%s %s>\n" % ("  " * self.level[0], self.tagname, self.attr))
        else:
            self.fh.write("%s<%s>\n" % ("  " * self.level[0], self.tagname))
        self.level[0] +=1


    def __exit__(self, tpe, value, traceback):
        self.level[0] -=1
        self.fh.write("%s</%s>\n" % ("  " * self.level[0], self.tagname))


class XMLFile(object):
    def __init__(self, fh):
        self.level = [0]
        self.fh = fh
        fh.write('<?xml version="1.0" encoding="UTF-8"?>\n')


    def tag(self, name, attr=None):
        return XMLTag(self.level, self.fh, name, attr=attr)


    def write(self, s):
        return self.fh.write(s)


    def writetag(self, tagname, s):
        self.fh.write("%s<%s>%s</%s>\n" % ("  " * self.level[0], tagname, s, tagname))


class ContentDumper(n5core.endpoint.Endpoint):
    def __init__(self):
        self.baseurl = 'http://localhost:8092/noark5v4/'
        self.savedir = "tmp"
        parser = argparse.ArgumentParser()
        parser.add_argument("--baseurl", help="(default is %s)" % self.baseurl)
        parser.add_argument("--xml", help="(default is false)",
                            default=False, action="store_true")
        parser.add_argument("--savedir", help="(default is %s)" % self.savedir)
        parser.add_argument("--verbose", help="enable debug output",
                            action="store_true")
        args = parser.parse_args()
        if args.baseurl:
            self.baseurl = args.baseurl
        if args.savedir:
            self.savedir = args.savedir
        n5core.endpoint.Endpoint.__init__(self,self.baseurl)
        self.verbose = args.verbose
        self.xml = args.xml
        
    def _mkdir_recursive(self, path):
        sub_path = os.path.dirname(path)
        if "" != sub_path and not os.path.exists(sub_path):
            self._mkdir_recursive(sub_path)
        if not os.path.exists(path):
            os.mkdir(path)



    def recurse_xml_konvertering(self, output, content):
        with output.tag('konvertering'):
            # FIXME
            pass


    def recurse_xml_dokumentobjekt(self, output, content):
        with output.tag('dokumentobjekt'):
            if self.verbose:
                print(content)
            for k, v in content.items():
                if '_links' != k:
                    output.writetag(k, v)
            konvrel = '%sarkivstruktur/konvertering/' % self.relbaseurl
            filrel = '%sarkivstruktur/fil/' % self.relbaseurl
            subs = {
# FIXME ikke implementert i Nikita
#                konvrel: self.recurse_xml_konvertering,
            }
            for rel in subs.keys():
                if rel in content['_links']:
                    (c, res) = self.json_get(content['_links'][rel]['href'])
                    info = json.loads(c)
                    if self.verbose:
                        print(info)
                    if 'count' not in info or 0 < info['count']:
                        for sub in info['results']:
                            subs[rel](output, sub)
            if filrel in content['_links']:
                self._mkdir_recursive("%s/DOKUMENT" % self.savepath)
                filename = "%s-%s" % (content['sjekksumAlgoritme'], content['sjekksum'])
                with open('%s/DOKUMENT/%s' % (self.savepath, filename), 'w') as fh:
                    (data, r) = self._get(content['_links'][filrel]['href'])
                    fh.write(data)
                output.writetag("referanseFil", "DOKUMENT/%s" % filename)


    def recurse_xml_dokumentbeskrivelse(self, output, content):
        with output.tag('dokumentbeskrivelse'):
            if self.verbose:
                print(content)
            for k, v in content.items():
                if '_links' != k:
                    output.writetag(k, v)
            dokobjrel = '%sarkivstruktur/dokumentobjekt/' % self.relbaseurl
            subs = {
                dokobjrel: self.recurse_xml_dokumentobjekt,
            }
            for rel in subs.keys():
                if rel in content['_links']:
                    (c, res) = self.json_get(content['_links'][rel]['href'])
                    info = json.loads(c)
    #                print(info)
                    if 'count' not in info or 0 < info['count']:
                        for sub in info['results']:
                            subs[rel](output, sub)


    def recurse_xml_korrespondansepart(self, output, content):
        with output.tag('korrespondansepart'):
            for k, v in content.items():
                if '_links' != k:
                    output.writetag(k, v)


    def recurse_xml_part(self, output, content):
        with output.tag('part'):
            for k, v in content.items():
                if '_links' != k:
                    output.writetag(k, v)


    def recurse_xml_registrering(self, output, content):
        with output.tag('registrering'):
            if self.verbose:
                print(content)
            for k, v in content.items():
                if '_links' != k:
                    output.writetag(k, v)
            dokbeskrrel = '%sarkivstruktur/dokumentbeskrivelse/' % self.relbaseurl
            partrel = '%sarkivstruktur/part/' % self.relbaseurl
            korrpartrel = '%ssakarkiv/korrespondansepart/' % self.relbaseurl
            subs = {
                dokbeskrrel: self.recurse_xml_dokumentbeskrivelse,
# FIXME not working in Nikita
#                partrel:     self.recurse_xml_part,
                korrpartrel: self.recurse_xml_korrespondansepart,
            }
            for rel in subs.keys():
                if rel in content['_links']:
                    (c, res) = self.json_get(content['_links'][rel]['href'])
                    info = json.loads(c)
                    if self.verbose:
                        print(info)
                    if 'count' not in info or 0 < info['count']:
                        for sub in info['results']:
                            subs[rel](output, sub)


    def recurse_xml_mappe(self, output, content):
        with output.tag('mappe'):
            if self.verbose:
                print(content)
            for k, v in content.items():
                if '_links' != k:
                    output.writetag(k, v)
            undermapperel = '%sarkivstruktur/undermappe/' % self.relbaseurl
            registreringrel = '%sarkivstruktur/registrering/' % self.relbaseurl
            partrel = '%sarkivstruktur/part/' % self.relbaseurl
            subs = {
                undermapperel:            self.recurse_xml_mappe,
                registreringrel:          self.recurse_xml_registrering,
# FIXME not working in Nikita
#                partrel:                  self.recurse_xml_part,
            }
            for rel in subs.keys():
                if rel in content['_links']:
                    (c, res) = self.json_get(content['_links'][rel]['href'])
                    info = json.loads(c)
                    if self.verbose:
                        print(info)
                    if 'count' not in info or 0 < info['count']:
                        for sub in info['results']:
                            subs[rel](output, sub)


    def recurse_xml_klasse(self, output, content):
        with output.tag('klasse'):
            for k, v in content.items():
                if '_links' != k:
                    output.writetag(k, v)
            underklasserel = '%sarkivstruktur/underklasse/' % self.relbaseurl
            mapperel = '%sarkivstruktur/mappe/' % self.relbaseurl
            registreringrel = '%sarkivstruktur/registrering/' % self.relbaseurl
            subs = {
                underklasserel:  self.recurse_xml_klase,
                mapperel:        self.recurse_xml_mappe,
                registreringrel: self.recurse_xml_registrering,
            }
            for rel in subs.keys():
                if rel in content['_links']:
                    (c, res) = self.json_get(content['_links'][rel]['href'])
                    info = json.loads(c)
                    if self.verbose:
                        print(info)
                    if 'count' not in info or 0 < info['count']:
                        for sub in info['results']:
                            subs[rel](output, sub)


    def recurse_xml_klassifikasjonssystem(self, output, content):
        with output.tag('klassifikasjonssystem'):
            for k, v in content.items():
                if '_links' != k:
                    output.writetag(k, v)
            klasserel = '%sarkivstruktur/klasse/' % self.relbaseurl
            subs = {
                klasserel: self.recurse_xml_klase,
            }
            for rel in subs.keys():
                if rel in content['_links']:
                    (c, res) = self.json_get(content['_links'][rel]['href'])
                    info = json.loads(c)
                    if self.verbose:
                        output.write(info)
                    if 'count' not in info or 0 < info['count']:
                        for sub in info['results']:
                            subs[rel](output, sub)


    def recurse_xml_arkivskaper(self, output, content):
        with output.tag('arkivskaper'):
            for k, v in content.items():
                if '_links' != k:
                    output.writetag(k, v)


    def recurse_xml_arkivdel(self, output, content):
        with output.tag('arkivdel'):
            if self.verbose:
                print(content)
            for k, v in content.items():
                if '_links' != k:
                    output.writetag(k, v)
            klassifikasjonssystemrel = '%sarkivstruktur/arkivdel/' % self.relbaseurl
            mapperel = '%sarkivstruktur/mappe/' % self.relbaseurl
            saksmapperel = '%sarkivstruktur/saksmappe/' % self.relbaseurl
            registreringrel = '%sarkivstruktur/arkivskaper/' % self.relbaseurl
            subs = {
                klassifikasjonssystemrel: self.recurse_xml_klassifikasjonssystem,
                mapperel:                 self.recurse_xml_mappe,
                saksmapperel:             self.recurse_xml_mappe,
                registreringrel:          self.recurse_xml_registrering,
            }
            for rel in subs.keys():
                if rel in content['_links']:
                    (c, res) = self.json_get(content['_links'][rel]['href'])
                    info = json.loads(c)
                    if 'count' not in info or 0 < info['count']:
                        for sub in info['results']:
                            subs[rel](output, sub)


    def recurse_xml_arkiv(self, output, content, first=False):
        attr = None
        if first:
            attr = 'xmlns="http://www.arkivverket.no/standarder/noark5/arkivstruktur" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"'
        with output.tag('arkiv', attr=attr):
            for k, v in content.items():
                if '_links' != k:
                    output.writetag(k, v)
            underarkivrel = '%sarkivstruktur/underarkiv/' % self.relbaseurl
            arkivdelrel = '%sarkivstruktur/arkivdel/' % self.relbaseurl
            arkivskaperrel = '%sarkivstruktur/arkivskaper/' % self.relbaseurl
            subs = {
                underarkivrel: self.recurse_xml_arkiv,
                arkivdelrel:   self.recurse_xml_arkivdel,
                arkivskaperrel:self.recurse_xml_arkivskaper,
            }
            for rel in subs.keys():
                if rel in content['_links']:
                    (c, res) = self.json_get(content['_links'][rel]['href'])
                    info = json.loads(c)
                    if self.verbose:
                        print(info)
                    if 'count' not in info or 0 < info['count']:
                        for sub in info['results']:
                            subs[rel](output, sub)


    def recurse_xml(self):
        try:
            self.login()
        except n5core.endpoint.LoginFailure:
            pass
        arkivhref = self.findRelation('%sarkivstruktur/arkiv/' % self.relbaseurl)
        print(arkivhref)
        (c, res) = self.json_get(arkivhref)
        arkivinfo = json.loads(c)
        print(arkivinfo)

        if 'count' not in arkivinfo or 0 < arkivinfo['count']:
            for arkiv in arkivinfo['results']:
                utcnow = datetime.datetime.utcnow().replace(microsecond=0, tzinfo=pytz.utc)
                self.savepath = "uttrekk-arkiv-%s-%s" % (arkiv['systemID'], utcnow.isoformat())
                self._mkdir_recursive(self.savepath)
                with open('%s/arkivstruktur.xml' % self.savepath, 'w') as fh:
                    output = XMLFile(fh)
                    self.recurse_xml_arkiv(output, arkiv, first=True)


    def recurse(self):
        try:
            self.login()
        except n5core.endpoint.LoginFailure:
            pass
        print("Saving to %s" % self.savedir)
        urlsleft = ['.']
        urlseen = {}
        urlsrc = {'.': 'root'}
        while 0 < len(urlsleft):
            url = urlsleft.pop(0)
            if url in urlseen:
                continue
            urlseen[url] = 1
            
            path = url.replace(self.baseurl, "")
            path = path.rstrip('/').replace('/.', '/index')
            path = path + ".json"
            path = os.path.join(self.savedir, path)
            if -1 != path.find('//') or '/' == path[0]:
                print("error: bogus url %s seen in %s (path %s)" % ( url, urlsrc[url], path))
                continue
            
            try:
                if self.verbose:
                    print("info: Fetching %s" % url)
                else:
                    sys.stdout.write('.')
                    sys.stdout.flush()
                (content, res) = self.json_get(url)

                if self.verbose:
                    print("info: Creating %s for %s" % (path, url))
                dir = os.path.dirname(path)
                self._mkdir_recursive(dir)
                f = open(path, 'w')
                f.write(content)
                f.close()
                
                ctype = res.info().getheader('Content-Type')
                if ctype is None:
                    print("error: No Content-Type from %s" % url)
                if ctype is None or 0 != ctype.find('application/vnd.noark5-v4+json'):
                    print("info: ignoring %s" % url)
                else:
                    try:
                        baseref = json.loads(content)
                    except ValueError as e:
                        print('error: non-JSON content returned for %s' % url)
                        baseref = None
                    if baseref is None:
                        print("error: JSON MIME type but no JSON in %s" % url)
                    elif type(baseref) is list:
                        print("error: found json list in %s" % url)
                    elif '_links' in baseref:
                        for l in baseref['_links']:
                            if 'href' in l:
                                href = l['href']
                                if 'templated' in l and l['templated']:
                                    href = href.split('{')[0]
                                if href not in urlseen:
                                    urlsleft.append(href)
                                    if href not in urlsrc:
                                        urlsrc[href] = []
                                    urlsrc[href].append(url)
                    if baseref is not None and type(baseref) is not list:
                        for basekey in baseref.keys():
                            if basekey != '_links' and type(baseref[basekey]) is list:
                                for element in baseref[basekey]:
                                    if '_links' in element and len(element['_links']) > 0:
                                        for l in element['_links']:
                                            href = l['href']
                                            if href not in urlseen:
                                                urlsleft.append(href)
                                                if href not in urlsrc:
                                                    urlsrc[href] = []
                                                urlsrc[href].append(url)
            except urllib2.HTTPError as e:
                pass
        if not self.verbose:
            print("")

def main():
    t = ContentDumper()
    if t.xml:
        return t.recurse_xml()
    else:
        return t.recurse()

if __name__ == '__main__':
    exit(main())
