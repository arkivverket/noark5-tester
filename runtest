#!/usr/bin/python
# -*- coding: utf-8 -*-

"""

Connect to the REST API of a Noark 5 service and check that it behaves
as it should.  See also http://rel.kxml.no/noark5/konformitetsniva/

"""
# Copyright (C) 2017 Petter Reinholdtsen <pere@hungry.com>
#
# Licensed under the GNU General Public License Version 2
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.

import sys
sys.path.append('lib')

import argparse
import datetime
from hashlib import sha256
import json
import mechanize
import os
import re
from subprocess import call
import urllib2
import urlparse
import xml.etree.ElementTree
import n5core.endpoint

noarkrelbase = 'http://rel.kxml.no/noark5/v4/api/'
nikitarelbase = 'http://nikita.arkivlab.no/noark5/v4/'

class Noark5Tester (n5core.endpoint.Endpoint):
    knownrels = [
        noarkrelbase + 'admin/administrativenhet/',
        noarkrelbase + 'admin/bruker/',
        noarkrelbase + 'admin/enhet/',
        noarkrelbase + 'admin/ny-administrativenhet/',
        noarkrelbase + 'admin/ny-bruker/',
        noarkrelbase + 'admin/ny-rettighet/',
        noarkrelbase + 'admin/rettighet/',
        noarkrelbase + 'arkivstruktur/',
        noarkrelbase + 'arkivstruktur/arkiv/',
        noarkrelbase + 'arkivstruktur/arkivdel/',
        noarkrelbase + 'arkivstruktur/arkivskaper/',
        noarkrelbase + 'arkivstruktur/basisregistrering/',
        noarkrelbase + 'arkivstruktur/bygning/',
        noarkrelbase + 'arkivstruktur/dokumentbeskrivelse/',
        noarkrelbase + 'arkivstruktur/dokumentobjekt/',
        noarkrelbase + 'arkivstruktur/elektronisksignatur/',
        noarkrelbase + 'arkivstruktur/fil/',
        noarkrelbase + 'arkivstruktur/hendelseslogg/',
        noarkrelbase + 'arkivstruktur/klasse/',
        noarkrelbase + 'arkivstruktur/klassifikasjonssystem/',
        noarkrelbase + 'arkivstruktur/konvertering/',
        noarkrelbase + 'arkivstruktur/kryssreferanse/',
        noarkrelbase + 'arkivstruktur/logg/',
        noarkrelbase + 'arkivstruktur/mappe/',
        noarkrelbase + 'arkivstruktur/matrikkel/',
        noarkrelbase + 'arkivstruktur/merknad/',
        noarkrelbase + 'arkivstruktur/nasjonaleidentifikator/',
        noarkrelbase + 'arkivstruktur/nasjonalidentifikator/',
        noarkrelbase + 'arkivstruktur/ny-arkiv/',
        noarkrelbase + 'arkivstruktur/ny-arkivdel/',
        noarkrelbase + 'arkivstruktur/ny-arkivskaper/',
        noarkrelbase + 'arkivstruktur/ny-basisregistrering/',
        noarkrelbase + 'arkivstruktur/ny-bygning/',
        noarkrelbase + 'arkivstruktur/ny-dokumentbeskrivelse/',
        noarkrelbase + 'arkivstruktur/ny-dokumentobjekt/',
        noarkrelbase + 'arkivstruktur/ny-elektronisksignatur/',
        noarkrelbase + 'arkivstruktur/ny-hendelseslogg/',
        noarkrelbase + 'arkivstruktur/ny-klasse/',
        noarkrelbase + 'arkivstruktur/ny-klassifikasjonssystem/',
        noarkrelbase + 'arkivstruktur/ny-konvertering/',
        noarkrelbase + 'arkivstruktur/ny-kryssreferanse/',
        noarkrelbase + 'arkivstruktur/ny-mappe/',
        noarkrelbase + 'arkivstruktur/ny-matrikkel/',
        noarkrelbase + 'arkivstruktur/ny-merknad/',
        noarkrelbase + 'arkivstruktur/ny-nasjonalidentifikator',
        noarkrelbase + 'arkivstruktur/ny-plan/',
        noarkrelbase + 'arkivstruktur/ny-posisjon/',
        noarkrelbase + 'arkivstruktur/ny-registrering/',
        noarkrelbase + 'arkivstruktur/plan/',
        noarkrelbase + 'arkivstruktur/posisjon/',
        noarkrelbase + 'arkivstruktur/registrering/',
        noarkrelbase + 'arkivstruktur/sekundaerklassifikasjons',
        noarkrelbase + 'arkivstruktur/underarkiv/',
        noarkrelbase + 'arkivstruktur/underklasse/',
        noarkrelbase + 'arkivstruktur/undermappe/',
        noarkrelbase + 'loggingogsporing/endringslogg/',
        noarkrelbase + 'loggingogsporing/ny-endringslogg/',
        noarkrelbase + 'metadata/arkivdelstatus/',
        noarkrelbase + 'metadata/arkivstatus/',
        noarkrelbase + 'metadata/avskrivningsmaate/',
        noarkrelbase + 'metadata/dokumentmedium/',
        noarkrelbase + 'metadata/dokumentstatus/',
        noarkrelbase + 'metadata/dokumenttype/',
        noarkrelbase + 'metadata/elektronisksignatursikkerhetsnivaa/',
        noarkrelbase + 'metadata/elektronisksignaturverifisert/',
        noarkrelbase + 'metadata/flytstatus/',
        noarkrelbase + 'metadata/format/',
        noarkrelbase + 'metadata/graderingskode/',
        noarkrelbase + 'metadata/hendelsetype/',
        noarkrelbase + 'metadata/journalposttype/',
        noarkrelbase + 'metadata/journalstatus/',
        noarkrelbase + 'metadata/kassasjonsvedtak/',
        noarkrelbase + 'metadata/klassifikasjonstype/',
        noarkrelbase + 'metadata/korrespondanseparttype/',
        noarkrelbase + 'metadata/land/',
        noarkrelbase + 'metadata/mappetype/',
        noarkrelbase + 'metadata/merknadstype/',
        noarkrelbase + 'metadata/moetedeltakerfunksjon/',
        noarkrelbase + 'metadata/moeteregistreringsstatus/',
        noarkrelbase + 'metadata/moeteregistreringstype/',
        noarkrelbase + 'metadata/moetesakstype/',
        noarkrelbase + 'metadata/postnummer/',
        noarkrelbase + 'metadata/presedensstatus/',
        noarkrelbase + 'metadata/sakspartrolle/',
        noarkrelbase + 'metadata/saksstatus/',
        noarkrelbase + 'metadata/skjermingdokument/',
        noarkrelbase + 'metadata/skjermingmetadata/',
        noarkrelbase + 'metadata/slettingstype/',
        noarkrelbase + 'metadata/tilgangskategori/',
        noarkrelbase + 'metadata/tilgangsrestriksjon/',
        noarkrelbase + 'metadata/tilknyttetregistreringsom/',
        noarkrelbase + 'metadata/variantformat/',
        noarkrelbase + 'sakarkiv/',
        noarkrelbase + 'sakarkiv/avskrivning/',
        noarkrelbase + 'sakarkiv/dokumentflyt/',
        noarkrelbase + 'sakarkiv/enkeladresse/',
        noarkrelbase + 'sakarkiv/journalpost/',
        noarkrelbase + 'sakarkiv/kontaktinformasjon/',
        noarkrelbase + 'sakarkiv/korrespondansepart/',
        noarkrelbase + 'sakarkiv/korrespondansepartenhet/',
        noarkrelbase + 'sakarkiv/korrespondansepartintern/',
        noarkrelbase + 'sakarkiv/korrespondansepartperson/',
        noarkrelbase + 'sakarkiv/ny-avskrivning/',
        noarkrelbase + 'sakarkiv/ny-dokumentflyt/',
        noarkrelbase + 'sakarkiv/ny-enkeladresse/',
        noarkrelbase + 'sakarkiv/ny-journalpost/',
        noarkrelbase + 'sakarkiv/ny-kontaktinformasjon/',
        noarkrelbase + 'sakarkiv/ny-korrespondansepart/',
        noarkrelbase + 'sakarkiv/ny-korrespondansepartenhet/',
        noarkrelbase + 'sakarkiv/ny-korrespondansepartintern/',
        noarkrelbase + 'sakarkiv/ny-korrespondansepartperson/',
        noarkrelbase + 'sakarkiv/ny-presedens/',
        noarkrelbase + 'sakarkiv/ny-saksmappe/',
        noarkrelbase + 'sakarkiv/ny-sakspart/',
        noarkrelbase + 'sakarkiv/ny-sakspartenhet/',
        noarkrelbase + 'sakarkiv/ny-sakspartperson/',
        noarkrelbase + 'sakarkiv/presedens/',
        noarkrelbase + 'sakarkiv/sak/',
        noarkrelbase + 'sakarkiv/saksmappe/',
        noarkrelbase + 'sakarkiv/sakspart/',
        noarkrelbase + 'sakarkiv/sakspartenhet/',
        noarkrelbase + 'sakarkiv/saksparter/',
        noarkrelbase + 'sakarkiv/sakspartperson/',
        noarkrelbase + 'sakarkiv/sekundaerklassifikasjon/',
        'self',
    ]
    knownmissingregex = [
        'hateoas-api/arkivstruktur/arkiv/[-0-9a-z]+/arkiv/?',
        'hateoas-api/arkivstruktur/arkiv/[-0-9a-z]+/arkivskaper/?',
        'hateoas-api/arkivstruktur/arkiv/[-0-9a-z]+/ny-underarkiv/?',
        'hateoas-api/arkivstruktur/arkiv/[-0-9a-z]+/underarkiv/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/arkiv/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/forloeper/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/gradering/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/kassasjon/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/klassifikasjonssystem/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/ny-arvtager/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/ny-forloeper/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/ny-gradering/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/ny-kassasjon/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/ny-klassifikasjonssystem/',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/ny-oppbevaringssted/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/ny-oppbevaringssteder/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/ny-registrering/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/ny-skjerming/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/ny-sletting/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/ny-utfoertKassasjon/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/oppbevaringssted/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/referanseArvtager/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/saksmappe/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/skjerming/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/sletting/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/utfoertKassasjon/?',
        'hateoas-api/arkivstruktur/arkivdel/[-0-9a-z]+/registrering/?',
        'hateoas-api/arkivstruktur/basisregistrering/[-0-9a-z]+/ny-forfatter/?',
        'hateoas-api/arkivstruktur/basisregistrering/[-0-9a-z]+/ny-kryssreferanse/?',
        'hateoas-api/arkivstruktur/basisregistrering/[-0-9a-z]+/ny-merknad/?',
        'hateoas-api/arkivstruktur/basisregistrering/[-0-9a-z]+/ny-noekkelord/?',
        'hateoas-api/arkivstruktur/basisregistrering/[-0-9a-z]+/ny-oppbevaringssted/?',
        'hateoas-api/arkivstruktur/dokumentbeskrivelse/[-0-9a-z]+/forfatter/?',
        'hateoas-api/arkivstruktur/dokumentbeskrivelse/[-0-9a-z]+/merknad/?',
        'hateoas-api/arkivstruktur/dokumentbeskrivelse/[-0-9a-z]+/ny-forfatter/?',
        'hateoas-api/arkivstruktur/dokumentbeskrivelse/[-0-9a-z]+/ny-gradering/?',
        'hateoas-api/arkivstruktur/dokumentbeskrivelse/[-0-9a-z]+/ny-kassasjon/?',
        'hateoas-api/arkivstruktur/dokumentbeskrivelse/[-0-9a-z]+/ny-merknad/?',
        'hateoas-api/arkivstruktur/dokumentbeskrivelse/[-0-9a-z]+/ny-oppbevaringssted/?',
        'hateoas-api/arkivstruktur/dokumentbeskrivelse/[-0-9a-z]+/ny-skjerming/?',
        'hateoas-api/arkivstruktur/dokumentbeskrivelse/[-0-9a-z]+/ny-sletting/?',
        'hateoas-api/arkivstruktur/dokumentbeskrivelse/[-0-9a-z]+/ny-utfoertKassasjon/?',
        'hateoas-api/arkivstruktur/dokumentbeskrivelse/[-0-9a-z]+/oppbevaringssted/?',
        'hateoas-api/arkivstruktur/dokumentbeskrivelse/[-0-9a-z]+/registrering/?',
        'hateoas-api/arkivstruktur/dokumentobjekt/[-0-9a-z]+/dokumentbeskrivelse/?',
        'hateoas-api/arkivstruktur/dokumentobjekt/[-0-9a-z]+/elektronisksignatur/?',
        'hateoas-api/arkivstruktur/dokumentobjekt/[-0-9a-z]+/konvertering/?',
        'hateoas-api/arkivstruktur/dokumentobjekt/[-0-9a-z]+/ny-elektronisksignatur/?',
        'hateoas-api/arkivstruktur/dokumentobjekt/[-0-9a-z]+/ny-konvertering/?',
        'hateoas-api/arkivstruktur/dokumentobjekt/[-0-9a-z]+/referanseFil/?',
        'hateoas-api/arkivstruktur/dokumentobjekt/[-0-9a-z]+/registrering/?',
        'hateoas-api/arkivstruktur/mappe/[-0-9a-z]+/arkivdel/?',
        'hateoas-api/arkivstruktur/mappe/[-0-9a-z]+/avslutt-mappe/?',
        'hateoas-api/arkivstruktur/mappe/[-0-9a-z]+/basisregistrering/?',
        'hateoas-api/arkivstruktur/mappe/[-0-9a-z]+/kryssreferanse/?',
        'hateoas-api/arkivstruktur/mappe/[-0-9a-z]+/merknad/?',
        'hateoas-api/arkivstruktur/mappe/[-0-9a-z]+/ny-klassereferanse/?',
        'hateoas-api/arkivstruktur/mappe/[-0-9a-z]+/ny-klassifikasjonssystem/?',
        'hateoas-api/arkivstruktur/mappe/[-0-9a-z]+/ny-kryssreferanse/?',
        'hateoas-api/arkivstruktur/mappe/[-0-9a-z]+/ny-merknad/?',
        'hateoas-api/arkivstruktur/mappe/[-0-9a-z]+/ny-undermappe/?',
        'hateoas-api/arkivstruktur/mappe/[-0-9a-z]+/referanseKlasse/?',
        'hateoas-api/arkivstruktur/mappe/[-0-9a-z]+/sekundaerklassifikasjon/?',
        'hateoas-api/arkivstruktur/mappe/[-0-9a-z]+/undermappe/?',
        'hateoas-api/arkivstruktur/mappe/[-0-9a-z]+/utvid-til-moetemappe/?',
        'hateoas-api/arkivstruktur/mappe/[-0-9a-z]+/utvid-til-saksmappe/?',
        'hateoas-api/arkivstruktur/registrering/[-0-9a-z]+/dokumentobjekt/?',
        'hateoas-api/arkivstruktur/registrering/[-0-9a-z]+/gradering/?',
        'hateoas-api/arkivstruktur/registrering/[-0-9a-z]+/kassasjon/?',
        'hateoas-api/arkivstruktur/registrering/[-0-9a-z]+/ny-gradering/?',
        'hateoas-api/arkivstruktur/registrering/[-0-9a-z]+/ny-kassasjon/?',
        'hateoas-api/arkivstruktur/registrering/[-0-9a-z]+/ny-referanseArkivdel/?',
        'hateoas-api/arkivstruktur/registrering/[-0-9a-z]+/ny-skjerming/?',
        'hateoas-api/arkivstruktur/registrering/[-0-9a-z]+/ny-sletting/?',
        'hateoas-api/arkivstruktur/registrering/[-0-9a-z]+/ny-utfoertKassasjon/?',
        'hateoas-api/arkivstruktur/registrering/[-0-9a-z]+/referanseArkivdel/?',
        'hateoas-api/arkivstruktur/registrering/[-0-9a-z]+/skjerming/?',
        'hateoas-api/arkivstruktur/registrering/[-0-9a-z]+/sletting/?',
        'hateoas-api/arkivstruktur/registrering/[-0-9a-z]+/utfoertKassasjon/?',
        'hateoas-api/metadata/dokumentstatus/?',
        'hateoas-api/metadata/dokumenttype/?',
        'hateoas-api/metadata/format/?',
        'hateoas-api/metadata/variantformat/?',
        'hateoas-api/sakarkiv/journalpost/[-0-9a-z]+/ny-avskrivning/',
        'hateoas-api/sakarkiv/journalpost/[-0-9a-z]+/avskrivning/?',
        'hateoas-api/sakarkiv/journalpost/[-0-9a-z]+/dokumentflyt/?',
        'hateoas-api/sakarkiv/journalpost/[-0-9a-z]+/elektronisksignatur/?',
        'hateoas-api/sakarkiv/journalpost/[-0-9a-z]+/ny-dokumentflyt/?',
        'hateoas-api/sakarkiv/journalpost/[-0-9a-z]+/ny-elektronisksignatur/?',
        'hateoas-api/sakarkiv/journalpost/[-0-9a-z]+/ny-korrespondansepartintern/',
        'hateoas-api/sakarkiv/journalpost/[-0-9a-z]+/ny-presedens/?',
        'hateoas-api/sakarkiv/journalpost/[-0-9a-z]+/presedens/?',
        'hateoas-api/sakarkiv/saksmappe/[-0-9a-z]+/journalpost/?',
        'hateoas-api/sakarkiv/saksmappe/[-0-9a-z]+/klasse/?',
        'hateoas-api/sakarkiv/saksmappe/[-0-9a-z]+/ny-klasse/?',
        'hateoas-api/sakarkiv/saksmappe/[-0-9a-z]+/ny-presedens/?',
        'hateoas-api/sakarkiv/saksmappe/[-0-9a-z]+/ny-sakspart/?',
        'hateoas-api/sakarkiv/saksmappe/[-0-9a-z]+/ny-saksstatus/?',
        'hateoas-api/sakarkiv/saksmappe/[-0-9a-z]+/ny-sekundaerklassifikasjon/?',
    ]
    verbose = False
    def __init__(self):
        baseurl = 'http://localhost:8092/noark5v4/'
        refurl = 'http://n5test.kxml.no/api/'
        parser = argparse.ArgumentParser()
        parser.add_argument("--baseurl", help="(default is %s)" % baseurl)
        parser.add_argument("--reference", help="set baseurl to to demo API site (override --baseurl)",
                            action="store_true")
        parser.add_argument("--verbose", help="enable debug output",
                            action="store_true")
        parser.add_argument("--keep", help="do not delete created objects",
                            action="store_true")
        args = parser.parse_args()
        if args.reference:
            args.baseurl = refurl
        if args.baseurl:
            self.baseurl = args.baseurl
        else:
            self.baseurl = baseurl
        n5core.endpoint.Endpoint.__init__(self,self.baseurl)
        self.created = []
        self.verbose = args.verbose
        self.keeptestdata = args.keep
        self.failures = {}
        self.xfailures = {}
        self.successes = {}
    def success(self, msg):
        if msg not in self.successes:
            self.successes[msg] = 1
            print "success: " + msg
        return True
    def failure(self, msg):
        if msg not in self.failures:
            self.failures[msg] = 1
            print "failure: " + msg
        return False
    def verify(self, check, msg):
        if (check):
            return self.success(msg)
        else:
            return self.failure(msg)
    def xfailure(self, msg):
        if msg not in self.xfailures:
            self.xfailures[msg] = 1
            print "xfailure: " + msg
        return False
    def xverify(self, check, msg):
        if (check):
            return self.success(msg)
        else:
            return self.xfailure(msg)

    def isknownmissing(self, url):
        for pattern in self.knownmissingregex:
            fullpattern = self.baseurl + pattern
            if re.match(fullpattern, url) is not None:
                return True
        return False

    def verifyuniquerels(self, links, url):
        currels = {}
        for l in links:
            rel = l['rel']
            if rel in currels:
                self.failure("duplicate rel %s in _links for %s" % (rel, url))
            else:
                currels[l['rel']] = url

    def recursiveHateoas(self):
        if self.verbose:
            print "recursively discovering standard URLs from the top"
        relok = {}
        for r in self.knownrels:
            relok[r] = True
        self.urls = []
        self.rels = {}
        urlsleft = ['.']
        urlseen = {}
        while 0 < len(urlsleft):
            url = urlsleft.pop(0)
            if url in urlseen:
                continue
            urlseen[url] = 1
            try:
                (content, res) = self.json_get(url)
                allow = res.info().getheader('Allow')
                self.success("GET %s worked with code %d"  % (url, res.code))
                self.verify(allow is not None, "GET header should include Allow for %s" % url)
                ctype = res.info().getheader('Content-Type')
                if self.verify(0 == ctype.find('application/vnd.noark5-v4+json'),
                               "MIME type %s should be application/vnd.noark5-v4+json for url %s" % (ctype, url)):
                    #print "C:", content
                    try:
                        baseref = json.loads(content)
                    except ValueError as e:
                        self.failure('non-JSON content returned for %s' % url)
                        baseref = None
                    #print "J:", baseref
                    if baseref is None:
                        self.failure("JSON MIME type but no JSON in %s" % url)
                    elif type(baseref) is list:
                        self.failure("found json list in %s" % url)
                    elif '_links' in baseref:
                        self.verifyuniquerels(baseref['_links'], url)
                        for l in baseref['_links']:
                            # Ignore non-standard relations
                            if 'href' in l \
                               and -1 == l['rel'].find("//rel.kxml.no/noark5/") \
                               and 'self' != l['rel']:
                                self.xfailure("unofficial relation %s" % l['rel'])
                            elif 'href' in l and \
                                 -1 != l['rel'].find("//rel.kxml.no/noark5/"):
                                href = l['href']
                                # The spec do not say if 'templated' is required or not
                                #if 'templated' not in l:
                                #    self.failure("_links missing templated in %s" % url)
                                if 'templated' in l and l['templated']:
                                    href = href.split('{')[0]
                                if href not in urlseen:
                                    urlsleft.append(href)
                                if 'rel' in l and l['rel'] != 'self':
                                    # FIXME figure out if rels should match spec
                                    if l['rel'] in relok:
                                        self.success('rel %s is well known' % l['rel'])
                                    elif l['rel'] + '/' in relok:
                                        self.success('rel %s is well known (missing trailing slash)' % l['rel'])
                                    else:
                                        self.failure('rel %s in %s should be well known' % (l['rel'], url))
                                    rel = l['rel']
                                    # Only check non-objects for unique relations
                                    if 'systemID' not in baseref \
                                       and rel in self.rels \
                                       and href != self.rels[rel]:
                                        self.failure("unique duplicate rel %s in _links for %s" % (rel, url))
                                    else:
                                        self.rels[rel] = href
                    else:
                        self.failure("GET %s missing _links" % url)
                    if baseref is not None and type(baseref) is not list:
                        for basekey in baseref.keys():
                            if basekey != '_links' and type(baseref[basekey]) is list:
                                for element in baseref[basekey]:
                                    #print(element)
                                    if '_links' in element and len(element['_links']) > 0:
                                        self.verifyuniquerels(element['_links'], url)
                                        for l in element['_links']:
                                            href = l['href']
                                            if href not in urlseen:
                                                #self.failure("Found new link %s" % href)
                                                urlsleft.append(href)
                self.urls.append(url)
                try:
                    # Check if CORS can work for the URL
                    (ocontent, ores) = self.options(url)
                    allow = []
                    allowstr = ores.info().getheader('Allow')
                    if allowstr:
                        allow = allowstr.split(',')
                        self.verify(-1 != allow.index('GET'), 'OPTIONS header Allow should include GET for %s' % url)
                    else:
                        self.failure("OPTIONS for URL %s missing Allow header" % url)
                except urllib2.HTTPError as e:
                    self.failure("OPTIONS failed for URL %s: %s" % (url, str(e)))
            except urllib2.HTTPError as e:
                if self.isknownmissing(url):
                    self.xfailure("unable to GET %s" % url)
                else:
                    self.failure("unable to GET %s" % url)

        for rel in sorted(self.rels.keys()):
            if self.verbose:
                print("mapping %s to %s" % (rel, self.rels[rel]))

    def verifyAuthentication(self):
        """
level 0 authentication.  Verify that a URL requiring login
will contain the WWW-Authenticate header and return HTTP
code 401 before logging in.
"""
        try:
            # FIXME figure out a way avoid hardcoding this URL
            url = "arkivstruktur/arkiv/"
            (content, res) = self.json_get(url)
            self.failure("level 0 accessing %s before login do not ask for basic authentication" % url)
        except urllib2.HTTPError, e:
            self.xverify(401 == e.code and 'www-authenticate' in e.hdrs,
                        "level 0 API should support support Basic access authentication")
        
    def verifyXML(self, prefix, xmlreq, xmlcontent):
        validlinktags = {
            '{http://www.kxml.no/rest/1.0}rel':1,
            '{http://www.kxml.no/rest/1.0}href':1,
            '{http://www.kxml.no/rest/1.0}type':1,
            '{http://www.kxml.no/rest/1.0}deprecation':1,
            '{http://www.kxml.no/rest/1.0}name':1,
            '{http://www.kxml.no/rest/1.0}title':1,
        }
        #print content
        #print xmlreq
        contenttype = xmlreq.info().getheader('Content-Type')
        if 0 != contenttype.find('application/vnd.noark5-v4+xml'):
            self.failure('level 0 XML - incorrect Content-Type for base: %s' % contenttype)
        else:
            self.success(prefix + ' - correct Content-Type for base')
            root = xml.etree.ElementTree.fromstring(xmlcontent)
            #print root.tag, root.attrib
            if self.xverify("{http://www.kxml.no/rest/1.0}Links" == root.tag, "root XML tag should be <Links xmlns=\"http://www.kxml.no/rest/1.0\" ...>"):
                for child in root:
                    if self.verify("{http://www.kxml.no/rest/1.0}Links" == child.tag, "first child XML tag should be <Links xmlns=\"http://www.kxml.no/rest/1.0\">"):
                        for subchild in child:
                            #print subchild.tag
                            if self.verify("{http://www.kxml.no/rest/1.0}link" == subchild.tag, "second child XML tag should be <links xmlns=\"http://www.kxml.no/rest/1.0\">"):
                                for link in subchild:
                                    #print link
                                    self.verify(link.tag in validlinktags,
                                                '<Links><Links><link> content should have well known tags')

    def testBasis(self):
        """
Test basis requirements for NOARK 5 Core.

"""
        # Verify CORS support,
        # https://en.wikipedia.org/wiki/Cross-origin_resource_sharing
        try:
            (ocontent, ores) = self.options('.')
            self.success("level 0 CORS - HTTP OPTTIONS request worked")
        except urllib2.HTTPError, e:
            self.failure("level 0 CORS - HTTP OPTTIONS request not working")
        except urllib2.URLError:
            self.failure("level 0 CORS - unable to connect via HTTP")

        self.verifyAuthentication()

        # Verify ability to produce XML output
        try:
            (content, res) = self.xml_get(".")
            self.verifyXML('level 0 XML', res, content)
        except urllib2.HTTPError, e:
            self.failure("level 0 XML - unable to GET content for base.")
            print("FAIL: %s" % e.read())

        # Verify ability to produce JSON output
        try:
            (content, res) = self.json_get(".")
            self.success("level 0 JSON - found base")
            contenttype = res.info().getheader('Content-Type')
            if 0 != contenttype.find('application/vnd.noark5-v4+json'):
                self.failure('level 0 JSON - incorrect content-type for base: %s' % contenttype)
            else:
                self.success('level 0 JSON - correct content-type for base')
                baseref = json.loads(content)
#                print d
                if '_links' in baseref:
                    self.success('level 0 JSON - found _links in json response')
                    return baseref
                else:
                    self.failure('level 0 JSON - did not find _links in json response')
        except urllib2.HTTPError, e:
            self.failure('level 0 JSON - unable to GET JSON content for base.')

        # FIXME Verify authentication, not sure how
        return None

    def parselinks(self,links):
        rels = {}
        for l in links:
            if 'href' in l and 'rel' in l:
                rels[l['rel']] = l['href']
        return rels

    def createEntity(self, name, rel, rels, data):
        if self.verbose:
            print("trying to create %s" % name)
        if rel not in rels:
            self.failure("unable to create a new %s, no %s entry discovered even if logged in" % (name, rel))
            return
        url = rels[rel]
        try:
            (gc, gres) = self.json_get(url)
            default = json.loads(gc)
            print("GET %s returned %s" % (url, default))
            # using default values in POST
            for k in default.keys():
                if not k == '_links' and k not in data:
                    data[k] = default[k]
            self.success("GET %s worked with code %d"  % (url, gres.code))
            try:
                # Verify OPTIONS announce POST support 
                (ocontent, ores) = self.options(url)
                allow = []
                allowstr = ores.info().getheader('Allow')
                if allowstr:
                    allow = allowstr.split(',')
                    verify(-1 != allow.index('POST'), 'OPTIONS header Allow should include POST for %s' % url)
                    verify(-1 != allow.index('GET'), 'OPTIONS header Allow should include GET for %s' % url)
                else:
                    self.failure("OPTIONS for URL %s missing Allow header" % url)
            except urllib2.HTTPError, e:
                self.failure('unable to OPTIONS %s' % url)
        except urllib2.HTTPError, e:
            self.failure('unable to GET %s' % url)
        print("POST %s: %s" % (url, data))
        try:
            (c, res) = self.json_post(url, data)
        except urllib2.HTTPError, e:
            self.failure("POST %s failed: %s" % (url, e.read().decode('UTF-8')))
            raise
        info = json.loads(c)
        id = info['systemID']
        self.verify(id is not None, "created %s" % name)
        self.verify(201 == res.code, "%s creation returned HTTP code 201" % name)
        self.verifyuniquerels(info['_links'], url)
        linkrefs = self.parselinks(info['_links'])
        self.verify('self' in linkrefs, "_links in response from %s creation should include 'self' reference" % name)
        if 'self' in linkrefs:
            selfurl = self.parselinks(info['_links'])['self']
            self.created.append(selfurl)
            # Make sure the 'self' url is GET-able
            try:
                extrainfo = self.json_get(selfurl)
                self.success("able to GET self url %s" % selfurl)
            except urllib2.HTTPError as e:
                self.failure("unable to GET self url %s" % selfurl)
        for k in data.keys():
            if self.verify(k in info,
                           "POST %s respons should have key %s" % (url, k)):
                if list is type(data[k]):
                    for v in data[k]:
                        self.verify(data[k][v] == info[k][v],
                                    "POST %s respons list member %s should match %s" %
                                    (url, k, v, data[k][v]))
                elif dict is type(data[k]):
                    for v in data[k].keys():
                        self.verify(data[k][v] == info[k][v],
                                    "POST %s respons dict %s key %s should match %s" %
                                    (url, k, v, data[k][v]))
                else:
                    self.verify(info[k] == data[k],
                                "POST %s response for '%s' should match '%s'" % (url, k, data[k]))
        return info
    def deleteCreated(self):
        for entityurl in self.created[::-1]:
            try:
                self.delete(entityurl)
                self.success("able to DELETE %s" % entityurl)
            except urllib2.HTTPError as e:
                # Until we figure out how sletting vs. DELETE should
                # work, make missing DELETE support an expected
                # failure.
                self.xfailure("unable to DELETE %s" % entityurl)

    def modifyAllCreated(self):
        for url in self.created:
            try:
                (infostr, res) = self.json_get(url)
                info = json.loads(infostr)
                etag = res.info().getheader('ETag')
                # FIXME remove strip() workaround for
                # https://github.com/HiOA-ABI/nikita-noark5-core/issues/77
                # when it is fixed.
                #etag = etag.strip('"')
                for key in info.keys():
                    keytype = type(info[key])
                    if list == keytype:
                        # list members are modified using other
                        # accessors.
                        print("removing key %s" % key)
                        info.pop(key, None)
                modkey = None
                for keycandidate in ('tittel',
                                     'navn',
                                     'arkivskaperNavn',
                                     'mimeType',
                                     'arkivertAv'):
                    if keycandidate in info:
                        modkey = keycandidate
                if modkey:
                    info[modkey] = info[modkey] + ' modified'
                else:
                    self.xfailure('unable to find anything to modify among %s' % info.keys())
                    print info
                infostr = json.dumps(info)
                putinfo = self.put(url, infostr,
                                   'application/vnd.noark5-v4+json',
                                   etag=etag)
                print putinfo
                self.success("able to modify %s" % url)
            except urllib2.HTTPError as e:
                self.failure("unable to modify %s" % url)

    def testDateFormats(self):
        """
Check if the API can handle all valid date and datetime formats.
The spec state that the API should handle all formats listed in
http://www.w3.org/TR/NOTE-datetime .  But this do not quite make
sense, as several of the valid values according to NODE-datetime are
not allowed by the Noark 5 standard XML metadata list, which refer
to date and datetime types in http://www.w3.org/2001/XMLSchema.

Also, should 'date' fields accept values with time of day in them,
or should it be rejected?

"""
        createfondsrel = noarkrelbase + 'arkivstruktur/ny-arkiv/'

        # FIXME Need to pick a object with 'date' and try to create it with variations
        datemust = []
        datecould = []
        datetimemust = [
            '1997-07-16T19:20+01:00', # From NOTE-datetime
            '1997-07-16T19:20:30+01:00', # From NOTE-datetime
            '1997-07-16T19:20:30.45+01:00', # From NOTE-datetime

            '2012-10-10T15:00:00', # From example extraction data sets
            '2014-11-22T15:15:02.956+01:00', # From example extraction data sets
        ]

        datetimecould = [
            '1997', # From NOTE-datetime, not accepted by XMLSChema date nor datetime
            '1997-07', # From NOTE-datetime, not accepted by XMLSChema date nor datetime
            '1997-07-16', # From NOTE-datetime accepted by XMLSChema date not datetime

            '1865-02-13T00:00:00Z', # From example extraction data sets
        ]

        for timevalues, level in [(datetimemust, self.failure), (datetimecould, self.xfailure)]:
            for timevalue in timevalues:
                try:
                    fondsdata = {
                        "avsluttetDato"        : timevalue,
                    }
                    fondinfo = self.createEntity('fonds', createfondsrel,
                                             self.rels, fondsdata)
                    if fondinfo:
                        self.success("able to create arkiv with opprettetDato='%s'" % timevalue)
                    else:
                        level("unable to create arkiv with opprettetDato='%s'" % timevalue)
                except urllib2.HTTPError as e:
                    level("unable to create arkiv with opprettetDato='%s'" % timevalue)

    def testNewDocument(self):
        now = datetime.datetime.now().isoformat()
        if not self.gotlogin:
            self.failure("not logged in, unable to test creation")
            return

        createrecordcreatorrel = noarkrelbase + 'arkivstruktur/ny-arkivskaper/'
        recordcreatordata = {
            #'arkivskaperID' : '123456789',
            #'arkivskaperNavn': 'Mr. arkivskaper',
            #'beskrivelse': 'fin fyr',
        }
        recordcreatorinfo = self.createEntity('recordcreator',
                                            createrecordcreatorrel, self.rels,
                                            recordcreatordata)
        if recordcreatorinfo is None:
            return
            
        createfondsrel = noarkrelbase + 'arkivstruktur/ny-arkiv/'
        fondsdata = {
            "tittel"          : "Title of the test fonds created %s" % now,
#            "beskrivelse"     : "Description of the test fonds",
#            "oppbevaringssted" : [ "location 1", "location2", "location3" ],
#            "dokumentmedium"  : "Elektronisk arkiv",
        }
        fondinfo = self.createEntity('fonds', createfondsrel,
                                     self.parselinks(recordcreatorinfo['_links']),
                                     fondsdata)
        if fondinfo is None:
            return
            
        seriesdata = {
            "tittel"          : "Title of the test series created %s" % now,
#            "beskrivelse"     : "Description of the test series",
#            "oppbevaringssted" : [ "location 1", "location2", "location3" ],
#            "dokumentmedium"  : "Elektronisk arkiv",
            "arkivdelstatus" : "O",
        }
        createseriesrel = noarkrelbase + 'arkivstruktur/ny-arkivdel/'
        serieinfo = self.createEntity('serie', createseriesrel,
                                      self.parselinks(fondinfo['_links']),
                                      seriesdata)
        
        filedata = {
#            "mappeID"            : "2017/01",
#            "offentligTittel"    : "Public title of the test file created %s" % now,
            "tittel"             : "Title of the test file created %s" % now,
#            "beskrivelse"        : "Description of the test file",
#            "noekkelord"         : ["nøkkelord 1", "nøkkelord 2"],
#            "oppbevaringssted"    : [ "location 1", "location2", "location3" ],
#            "dokumentmedium"     : "Elektronisk arkiv",
        }
        createfilerel = noarkrelbase + 'arkivstruktur/ny-mappe/'
        fileinfo = self.createEntity('file', createfilerel,
                                     self.parselinks(serieinfo['_links']),
                                     filedata)

        recorddata = {
        }
        createrecordrel = noarkrelbase + 'arkivstruktur/ny-registrering/'
        recordinfo = self.createEntity('record', createrecordrel,
                                       self.parselinks(fileinfo['_links']),
                                       recorddata)
        basicrecorddata = {
            "tittel"             : "Title of basic record created %s" % now,
#            "forfatter"          : [ "testforfatter"],
        }
        createbasicrecordrel = noarkrelbase + 'arkivstruktur/ny-basisregistrering/'
        basicrecordinfo = self.createEntity('basicrecord',
                                            createbasicrecordrel,
                                            self.parselinks(fileinfo['_links']),
                                            basicrecorddata)
        casefiledata = {
#            "mappeID"            : "2017/1",
#            "offentligTittel"    : "Public title of the test case file created %s" % now,
            "tittel"             : "Title of the test case file created %s" % now,
#            "beskrivelse"        : "Description of the test file",
#            "noekkelord"         : ["nøkkelord 1", "nøkkelord 2"],
#            "oppbevaringssted"    : [ "location 1", "location2", "location3" ],
#            "dokumentmedium"     : "Elektronisk arkiv",
#            "saksdato"           : "2016-10-04",
#            "administrativEnhet" : "The administrative unit",
#            "saksansvarlig"      : "Joe the case handler",
#            "saksstatus"         : "Opprettet",
        }
        createcasefilerel = noarkrelbase + 'sakarkiv/ny-saksmappe/'
        casefileinfo = self.createEntity('casefile', createcasefilerel,
                                         self.parselinks(serieinfo['_links']),
                                         casefiledata)
        casefileurl = self.parselinks(casefileinfo['_links'])['self']

        journalentrydata = {
            'tittel' : 'test',
        }
        # FIXME figure out how the spec expect us to add journalpost
        createjournalentryrel = nikitarelbase + 'ny-journalpost/'
        journalentryinfo = self.createEntity('journalentry',
                                             createjournalentryrel,
                                             self.parselinks(casefileinfo['_links']),
                                             journalentrydata)
        for (c, f) in [('enhet', 'navn'),
                       ('person', 'navn'),
                       # ('intern', 'administrativenhet') # FIXME not working yet
        ]:
            corrpartrel = noarkrelbase + 'sakarkiv/ny-korrespondansepart%s/' % c
            for code in ('EA', 'EM', 'EK', 'GM', 'IA', 'IM', 'IK'):
                corrdata = {
                    'korrespondanseparttype' : {
                        'kode' : code
                    },
                    f : 'Eksempel %s' % code,
                }
                corrinfo = self.createEntity('correspondance part %s' % c,
                                             corrpartrel,
                                             self.parselinks(journalentryinfo['_links']),
                                             corrdata)
        docdescdata = {
#            "dokumenttype"    : "type dokument",
#            "dokumentstatus"  : "status of document",
            "tittel"          : "Title of the test document description created %s" % now,
#            "tilknyttetRegistreringSom" : "Associated with record as"
            "dokumentnummer" : 1,
        }
        createdocdescrel = noarkrelbase + 'arkivstruktur/ny-dokumentbeskrivelse/'
        docdescinfo = self.createEntity('document description',
                                        createdocdescrel,
                                        self.parselinks(recordinfo['_links']),
                                        docdescdata)

        xmldata = "<?xml version=\"1.0\" encoding=\"UTF-8\"?><xml></xml>\n"
        hashalg = 'SHA-256'
        hasher = sha256()
        hasher.update(xmldata)
        hash = hasher.hexdigest()
        
        docobjdata = {
#            "versjonsnummer"  : 1,
#            "variantformat"   : "Arkivformat",
#            "format"          : "PDF",
#            "formatDetaljer"  : "PDF/A PDFv1.4",
            "sjekksum"          : hash,
            "sjekksumAlgoritme" : hashalg,
            "filstoerrelse"   : str(len(xmldata)),
#            "mimeType"       : "application/xml", 
        }
        createdocobjrel = noarkrelbase + 'arkivstruktur/ny-dokumentobjekt/'
        docobjinfo = self.createEntity('document object', createdocobjrel,
                                       self.parselinks(docdescinfo['_links']),
                                       docobjdata)

        # FIXME try to upload a file, for examle an xml file and large
        # chunked file.
        reffilerel = noarkrelbase + 'arkivstruktur/fil/'
        self.verify(reffilerel in self.parselinks(docobjinfo['_links']),
                    "_links in response from %s rel should include '%s' rel" % (createdocobjrel, reffilerel))
        rels = self.parselinks(docobjinfo['_links'])
        url = rels[reffilerel]
        try:
            (c, res) = self.post(url, xmldata, 'application/xml')
            # The spec is not clear on what is returned from file upload
            #self.verify(c == '', "POST %s return nothing" % url)
            self.verify(200 == res.code, "file upload returned HTTP code 200")
        except urllib2.HTTPError, e:
            print("POST %s failed: %s" % (url, e.read()))

        # Verify the pointer to the file to download
        (infostr, res) = self.json_get(rels['self'])
        docobjinfo2 = json.loads(infostr)
        if (self.verify(reffilerel in self.parselinks(docobjinfo2['_links']),
                        "_links in response from %s rel should include '%s' rel" % (createdocobjrel, reffilerel))):
            self.verify(self.parselinks(docobjinfo2['_links'])[reffilerel] == docobjinfo2['referanseDokumentfil'],
                        "referanseDokumentfil and _links->%s should have the same value (%s != %s)" %
                        (reffilerel, docobjinfo2['referanseDokumentfil'], self.parselinks(docobjinfo2['_links'])[reffilerel]))

        try:
            headers = { 'Accept' : 'application/xml' }
            (c, res) = self._get(url)
            self.verify(c == xmldata,
                        "downloaded file should match uploaded file")
            ctype = res.info().getheader('Content-Type')
            self.verify(0 == ctype.find('application/xml'),
                        "MIME type %s should be application/xml for url %s" %
                        (ctype, url))
        except urllib2.HTTPError as e:
            self.failure("downloading %s failed: %s" % (url, e.read()))

    def runtests(self):
        try:
            baseref = self.testBasis()
            self.recursiveHateoas()
            try:
                self.login()
                self.gotlogin = True
                self.success("able to log in using admin/password")
            except n5core.endpoint.LoginFailure as e:
                self.gotlogin = False
                self.failure("unable to log in, operating in read only mode: %s" % e)
            self.recursiveHateoas()

            # Disabled until we figure out exactly what kind of date
            # formats should be supported.
            self.testDateFormats()

            self.testNewDocument()
            self.recursiveHateoas()
            self.testNewDocument()
            self.modifyAllCreated()
            if not self.keeptestdata:
                self.deleteCreated()
        finally:
            print("%d successes, %d failures, %d expected failures"
                  % (len(self.successes.keys()),
                     len(self.failures.keys()),
                     len(self.xfailures.keys())))
        return not (0 == len(self.failures.keys()))
def main():
    t = Noark5Tester()
    return t.runtests()

if __name__ == '__main__':
    if os.path.isdir('.git'):
        call(["git", "rev-parse", "HEAD"])
    exit(main())
