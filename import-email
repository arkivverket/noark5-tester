#!/usr/bin/python
# -*- coding: utf-8 -*-

from __future__ import print_function

import sys
import time
sys.path.append('lib')

import argparse
import dateutil.parser
import email
from email.utils import parseaddr
import json
import mailbox
import urllib
import urllib2

import n5core.endpoint
from n5core.pick import pickUnlessOne

def decodeheader(s):
    if s is None:
        return s
    retval = None
    for ret, encoding in email.Header.decode_header(s):
        if encoding!=None:
            try:
                ret = ret.decode(encoding)
            except UnicodeDecodeError:
                pass # Ignore bogus headers, store them raw
        if retval is None:
            retval = ret
        else:
            retval += " " + ret
    return retval


def mime2format(mimestr):
    # Observed incorrectly spelled MIME types
    mimealias = {
        'image/jpg': 'image/jpeg',
        'plain/text': 'text/plain',
        'application/x-gzip': 'application/gzip',
    }
    # IANA register at
    # https://www.iana.org/assignments/media-types/media-types.xhtml
    mimetypemap = {
        'application/pdf':           'fmt/95',  # Registered MIME type
        'image/jpeg':                'fmt/41', # Registered MIME type
        'application/xml':           'fmt/101',  # Registered MIME type
        'text/xml':                  'fmt/101',  # Registered MIME type

        # These should have official codes, but do not
        'application/vnd.oasis.opendocument.presentation' : "fmt/138",
        'audio/x-wav':               'fmt/703',     # Not registered MIME type
        'image/png':                 'fmt/13',     # Registered MIME type
        'message/rfc822':            'fmt/278',  # Registered MIME type
        'text/csv':                  'x-fmt/18',     # Registered MIME type
        'text/x-diff':               'x-fmt/111',# Not registered MIME type
        'text/x-patch':              'x-fmt/111',# Not registered MIME type

        # No use splitting these formats out as separate upload, the
        # original email content is just fine and we are not going to
        # convert them to archive format anyway.
        'application/pgp-signature':   'ignore',  # Registered MIME type
        'application/pkcs7-signature': 'ignore',  # Registered MIME type
        'application/pgp-keys':        'ignore',  # Registered MIME type
        'text/plain':                None,      # Registered MIME type
        'text/html':                 None,      # Registered MIME type
        'multipart/mixed':             'ignore',  # Registered MIME type
        'multipart/signed':            'ignore',  # Registered MIME type
        'multipart/alternative':       'ignore',  # Registered MIME type
        'multipart/related':           'ignore',  # Registered MIME type

        # Not quite sure what to do with these
        'application/x-xz':          None,      # Not registered MIME type
        'application/octet-stream':  None,      # Registered MIME type
        'application/gzip':          None,      # Not registered MIME type
    }
    mimetype = mimestr.split(';')[0]
    if mimetype in mimealias:
        mimetype = mimealias[mimetype]
    if mimetype in mimetypemap:
        return mimetypemap[mimetype]
    return None

class MboxImporter(n5core.endpoint.Endpoint):
    def __init__(self):
        baseurl = 'http://localhost:8092/noark5v4/'
        self.mbox = 'input.mbox'
        parser = argparse.ArgumentParser()
        parser.add_argument("--baseurl", help="(default is %s)" % baseurl)
        parser.add_argument("--mta", help="behave as mta, read single email from stdin",
                            action="store_true")
        parser.add_argument("--mbox", help="(default is %s)" % self.mbox)
        parser.add_argument("--storageurl", help="specify under which URL (arkivdel/mappe) to store email files in")
        parser.add_argument("--saksmappe",
                            help="Store as saksmappe/journalpost instead of registrering/mappe",
                            action="store_true")
        parser.add_argument("--verbose", help="enable debug output",
                            action="store_true")
        args = parser.parse_args()
        self.usesaksmappe = args.saksmappe
        self.storageurl = args.storageurl
        if args.baseurl:
            baseurl = args.baseurl
        if args.mta and args.mbox:
            raise Exception("invalid combination of arguments, can not use --mta and --mbox together")
        if args.mbox:
            self.mbox = args.mbox
        self.mta = args.mta
        self.docobjurl = None
        self.parentmap = {}
        n5core.endpoint.Endpoint.__init__(self, baseurl)
        self.verbose = args.verbose


    def createEntity(self, name, rel, rels, data):
        if rel not in rels:
            raise Exception("unable to find %s in provided relations" % rel)
        url = rels[rel]['href']
        try:
            if self.verbose:
                print("GET %s" % url)
            (gc, gres) = self.json_get(url)
            default = json.loads(gc)
            for k in default.keys():
                if not k == '_links' and k not in data:
                    data[k] = default[k]
        except urllib2.HTTPError as e:
            pass
        try:
            if self.verbose:
                print("POST: %s" % data)
            (c, res) = self.json_post(url, data)
        except urllib2.HTTPError as e:
            raise
        info = json.loads(c)
        if self.verbose:
            # Validate the stuff we send came back after storing
            for f in data.keys():
                if data[f] is not None:
                    if  f not in info:
                        print("error: field %s=%s disappeared from object" %  (f, data[f]))
                    elif data[f] != info[f]:
                        print("error: field %s=%s do not match object value %s" %  (f, data[f], info[f]))
        return info

    def getDocObjUrl(self):
        """ Cache href to the list of dokumentobject """
        if not self.docobjurl:
            self.docobjurl = self.findRelation('%sarkivstruktur/dokumentobjekt/' % self.relbaseurl)
        return self.docobjurl

    def findSeries(self):
        """
Figure out which URL to use when creating one file per mail thread.

Store the info about the entity in self.seriesinfo
"""
        if self.storageurl:
            (c, res) = self.json_get(self.storageurl)
            self.seriesinfo = json.loads(c)
            return self.seriesinfo
        fondshref = self.findRelation('%sarkivstruktur/arkiv/' % self.relbaseurl)
        (c, res) = self.json_get(fondshref)
        fondsinfo = json.loads(c)
        info = pickUnlessOne(fondsinfo, 'arkiv')
        if info is None:
            return None

        seriesrel = '%sarkivstruktur/arkivdel/' % self.relbaseurl
        if seriesrel not in info['_links'] \
           or 'href' not in info['_links'][seriesrel]:
            print(info)
            raise Exception("missing from created dokumentobjekt: %s" % seriesrel)
        serieshref = info['_links'][seriesrel]['href']

        (c, res) = self.json_get(serieshref)
        seriesinfo = json.loads(c)
        #print()
        self.seriesinfo = pickUnlessOne(seriesinfo, 'arkivdel')
        if self.seriesinfo and self.verbose:
            print("serieurl: %s" % self.seriesinfo['_links']['self']['href'])
        return self.seriesinfo

    def alreadySaved(self, message):
        """
Look up email Message-Id in dokumentobjekt.filename, and return true
if a match is found.
        """
        self.getDocObjUrl()
        messageid = message['message-id']
        print("Looking for msgid: %s" % messageid)

        searchurl = self.docobjurl + '?filter=' +\
            urllib.quote_plus("filnavn eq '%s'" % messageid)
        print(searchurl)

        (s, res) = self.json_get(searchurl)
        docobjsinfo = json.loads(s)
        if 'results' in docobjsinfo:
            for d in docobjsinfo['results']:
                if 'filnavn' in d:
                    print("ID: %s" % d['filnavn'])
                    if  d['filnavn'] == messageid:
                          print("found message-id %s" % messageid)
                          return d
        return None

    def findThreadFile(self, message):
        """
Look up if any of the previous messages in a thread (using in-reply-to
and references) are already stored, and if so, return the file they
are in.
"""
        self.getDocObjUrl()
        thread = []
        if 'in-reply-to' in message:
            thread.append(message['in-reply-to'])
        if 'references' in message:
            for msgid in message['references'].replace("\n", " ").split(" "):
                if msgid != "":
                    thread.append(msgid)
        if 0 == len(thread):
            return  None
        #print(thread)
        
        matches = []
        for messageid in thread:
            searchurl = self.docobjurl + '?filter=' +\
                urllib.quote_plus("filnavn eq '%s'" % messageid)
            #print(searchurl)
        
            (s, res) = self.json_get(searchurl)
            docobjsinfo = json.loads(s)
            if 'results' in docobjsinfo:
                for d in docobjsinfo['results']:
                    if 'filnavn' in d:
                        if  d['filnavn'] == messageid:
                            print("found message-id %s" % messageid)
                            matches.append(d['systemID'])

        # FIXME Look up mappe/saksmappe containing docobj entries
        fileids = {}
        for docobjid in matches:
            if docobjid in self.parentmap:
                (docdescid, childtype, docdeschref) = self.parentmap[docobjid]
                if docdescid in self.parentmap:
                    (recordid, childtype, recordhref) = self.parentmap[docdescid]
                    if recordid in self.parentmap:
                        (fileid, childtype, filehref) = self.parentmap[recordid]
                        fileids[fileid] = filehref
        print("MappeID: ", fileids.keys())
        if 0 < len(fileids.keys()):
            # FIXME what if there are several files?
            filehref = fileids[fileids.keys()[0]]
            (fc, fres) = self.json_get(filehref)
            fileinfo = json.loads(fc)
            #print(fileinfo)
            return fileinfo
        return None

    def createNewFile(self, message):
        filedata = {
            'tittel' : decodeheader(message['subject']),
             # FIXME Workaround for bogus ny-* values
            'offentligTittel' : None,
            'beskrivelse' : None,
        }
        if self.usesaksmappe:
            casefilerel = '%ssakarkiv/ny-saksmappe/' % self.relbaseurl
            fileinfo = self.createEntity('saksmappe', casefilerel,
                                         self.seriesinfo['_links'],
                                         filedata)
        else:
            filerel = '%sarkivstruktur/ny-mappe/' % self.relbaseurl
            fileinfo = self.createEntity('mappe', filerel,
                                         self.seriesinfo['_links'],
                                         filedata)
        return fileinfo
    
    def recordMapping(self, parentinfo, childinfo, type):
        childid = childinfo['systemID']
        parentid = parentinfo['systemID']
        parenthref = parentinfo['_links']['self']['href']
        self.parentmap[childid] = (parentid, type, parenthref)


    def createDocumentObject(self, docdescinfo, docobjdata, content, created):
        docobjrel = '%sarkivstruktur/ny-dokumentobjekt/' % self.relbaseurl
        docobjinfo = self.createEntity('dokumentobjekt', docobjrel,
                                       docdescinfo['_links'],
                                       docobjdata)
        created.append(docobjinfo['_links']['self']['href'])
        self.recordMapping(docdescinfo, docobjinfo, 'dokumentobjekt')

        uploadrel = '%sarkivstruktur/fil/' % self.relbaseurl
        if uploadrel not in docobjinfo['_links'] \
           or 'href' not in docobjinfo['_links'][uploadrel]:
            print(docobjinfo)
            raise Exception("missing from created dokumentobjekt: %s" % uploadrel)

        newfilehref = docobjinfo['_links'][uploadrel]['href']

        # Make sure all parts going into the POST are type str by
        # converting newfilehref to str.  This avoid a
        # UnicodeDecodeError when the content is not UTF-8.
        try:
            (c, res) = self.post(str(newfilehref), content,
                                 docobjdata['mimeType'],
                                 length=len(content))
        except Exception as e:
            print("error: upload threw exception, removing object: %s %s" % (str(e),
                                                                             e.read()))
            for e in created[::-1]:
                self.delete(e)
            return False
        if 201 != res.code:
            print("error: upload failed (status == %d), removing objects"
                  % res.code)
            for e in created[::-1]:
                self.delete(e)
            return False
        return True

    def addMessageToFile(self, fileinfo, message):
        recordrel = '%sarkivstruktur/ny-registrering/' % self.relbaseurl
        recordentryrel = '%ssakarkiv/ny-journalpost/' % self.relbaseurl
        docdescrel = '%sarkivstruktur/ny-dokumentbeskrivelse/' % self.relbaseurl

        created = []
        content = message.as_string()
        
        messagelen = len(content)
        mimetype = "message/rfc822"
        format = mime2format(mimetype)

        threadstarterid = None
        if 'references' in message:
            threadstarterid = message['references'].strip().split()[0]
        elif 'in-reply-to' in message:
            threadstarterid = message['in-reply-to']
        else:
            threadstarterid = message['message-id']

        fromdate = dateutil.parser.parse(message['date']).isoformat()

        if self.usesaksmappe:
            recorddata = {
                'tittel' : decodeheader(message['subject']),
                "dokumentetsDato"      : fromdate,
                'sendtDato'            : fromdate, # what if date is faked?
                "journalposttype"      : 'I',
                # Workaround for bogus ny-* values
                'beskrivelse' : None,
            }
            recordinfo = self.createEntity('journalpost', recordentryrel,
                                           fileinfo['_links'],
                                           recorddata)
            created.append(recordinfo['_links']['self']['href'])
            self.recordMapping(fileinfo, recordinfo, 'journalpost')
            # FIXME consider journalpost and korrespondansepart (from
            # to/from/cc)
            corrpartrel = '%ssakarkiv/ny-korrespondansepartperson/' % self.relbaseurl
            parts = {
                'from' : 'EA',
                'to'   : 'EM',
                'cc'   : 'EK',
            }
            # FIXME should sort into KorrespondansepartEnhet,
            # KorrespondansepartPerson and KorrespondansepartIntern.
            # How can we do this?
            for part in parts:
                if part in message:
                    partstr = decodeheader(message[part])
                    for p in partstr.split(","):
                        navn, epost = parseaddr("From: %s" % p)
                        corrdata = {
                            'korrespondanseparttype' : {
                                'kode' : parts[part],
                            },
                            'navn' : navn,
                            'kontaktinformasjon' : { 'epostadresse' : epost},
                            'kontaktperson' : None,
                            'forretningsadresse' : {},
                            'postadresse' : {},
                        }
                        corrinfo = \
                            self.createEntity('correspondance part',
                                              corrpartrel,
                                              recordinfo['_links'],
                                              corrdata)

        else:
            recorddata = {
                'tittel' : decodeheader(message['subject']),
                'beskrivelse' : None,
            }
            recordinfo = self.createEntity('registrering', recordrel,
                                           fileinfo['_links'],
                                           recorddata)
            created.append(recordinfo['_links']['self']['href'])
            self.recordMapping(fileinfo, recordinfo, 'registrering')
        
        docdescdata = {
            'tittel' : decodeheader(message['subject']),
            'oppbevaringssted' : threadstarterid ,
        }
        docdescinfo = self.createEntity('dokumentbeskrivelse', docdescrel,
                                        recordinfo['_links'],
                                        docdescdata)
        created.append(docdescinfo['_links']['self']['href'])
        self.recordMapping(recordinfo, docdescinfo, 'dokumentbeskrivelse')
        
        docobjdata = {
            "versjonsnummer"  : str(0),
            "variantformat"   : "Produksjonsformat",
            "filstoerrelse"   : str(messagelen),
            "filnavn"         : message['message-id'],       
            "mimeType"        : mimetype,
        }
        if format:
            docobjdata["format"] = format
        if not self.createDocumentObject(docdescinfo, docobjdata,
                                         content, created):
            print("error: failed to create document object")
            return False
        if message.is_multipart():
            for part in message.walk():
                mimetype = part.get_content_type()
                format = mime2format(mimetype)
                if self.verbose:
                    print("info: mapping %s to %s" % (mimetype, format))
                # Do not store ignored attachments as separate
                # documents.  Everything else we upload and let the
                # kernel figure out what to do with them. :)
                if format is not None and 'ignore' != format:
                    continue
                content = part.get_payload(decode=True)
                if content is None:
                    continue
                contentlen = len(content)
                docobjdata = {
                    "versjonsnummer"  : str(0),
                    "variantformat"   : "Produksjonsformat",
                    "filstoerrelse"   : contentlen,
                    "filnavn"         : part.get_filename(),
                    "mimeType"        : mimetype,
                }
                if format:
                    docobjdata["format"] = format

                if not self.createDocumentObject(docdescinfo, docobjdata,
                                                 content, created):
                    print("error: failed to create document object for attachment %s"
                          % part.get_filename())

        return True

    def uploadEmail(self, message):
        docobjinfo = self.alreadySaved(message)
        if docobjinfo:
            print("email already part of archive")
            return False
        threadfile = self.findThreadFile(message)
        if not threadfile:
            # create new file
            threadfile = self.createNewFile(message)

        # Add to existing file
        return self.addMessageToFile(threadfile, message)

    def loadMbox(self):
        retval = True
        mbox = mailbox.mbox(self.mbox)
        last = time.time()
        count = 0
        for message in mbox:
            count = count + 1
            if not self.uploadEmail(message):
                print("error: failed to load email")
                retval = False
            now = time.time()
            print("%.2f s per insert/email (%d so far)" % (now - last, count))
            last = now
        return retval

    def loadEmail(self):
        """ Load a single email from stdin like /usr/sbin/sendmail does. """
        message = email.message_from_file(sys.stdin)
        if not self.uploadEmail(message):
            print("error: failed to load email")
            return False
        return True

    def load(self):
        if self.mta:
            return self.loadEmail()
        else:
            return self.loadMbox()

def main():
    t = MboxImporter()
    t.login()
    if t.findSeries() is None:
        print("error: unable to find arkivdel to use")
        return 1
    return t.load() != True

if __name__ == '__main__':
    exit(main())
